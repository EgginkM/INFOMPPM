{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š Recommendations based on Frequently Reviewed Together (association rules)\n",
    "For the final segment of this assignment, refer to section 5.4 of the _Practical Recommender Systems_ book (pages 113-127). After reading, download the code provided by the book and focus on the `association_rules_calculator.py` in the `builder` directory. Your task is to adapt this code for use in this notebook, translating its steps into a format suitable for our environment. Here's a simplified outline based on the source code:\n",
    "\n",
    "The steps found in the source code are:\n",
    "1. Load the data\n",
    "2. Generate transactions or, in our case reviews\n",
    "3. Calculate the Support Confidence\n",
    "4. Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "Instead of using a database, load your `.csv` files into a dataframe. Select the data necessary for identifying which user reviewed which books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/subset_ratings.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>28134</td>\n",
       "      <td>6575</td>\n",
       "      <td>006000438X</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>28142</td>\n",
       "      <td>6575</td>\n",
       "      <td>0060198133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>28143</td>\n",
       "      <td>6575</td>\n",
       "      <td>0060502258</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>28154</td>\n",
       "      <td>6575</td>\n",
       "      <td>0060926317</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>28155</td>\n",
       "      <td>6575</td>\n",
       "      <td>0060928336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53462</th>\n",
       "      <td>1081111</td>\n",
       "      <td>258534</td>\n",
       "      <td>074343627X</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53463</th>\n",
       "      <td>1081112</td>\n",
       "      <td>258534</td>\n",
       "      <td>0743437802</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53464</th>\n",
       "      <td>1081127</td>\n",
       "      <td>258534</td>\n",
       "      <td>0805062971</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53465</th>\n",
       "      <td>1081128</td>\n",
       "      <td>258534</td>\n",
       "      <td>0805063897</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53466</th>\n",
       "      <td>1081161</td>\n",
       "      <td>258534</td>\n",
       "      <td>1400033543</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1779 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  User-ID        ISBN  Book-Rating\n",
       "1237        28134     6575  006000438X            9\n",
       "1238        28142     6575  0060198133            8\n",
       "1239        28143     6575  0060502258            8\n",
       "1240        28154     6575  0060926317            2\n",
       "1241        28155     6575  0060928336            8\n",
       "...           ...      ...         ...          ...\n",
       "53462     1081111   258534  074343627X            9\n",
       "53463     1081112   258534  0743437802            9\n",
       "53464     1081127   258534  0805062971            7\n",
       "53465     1081128   258534  0805063897            7\n",
       "53466     1081161   258534  1400033543            7\n",
       "\n",
       "[1779 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users = df.groupby('User-ID')['ISBN'].count().reset_index(name='counts')\n",
    "users = list(df_users[(df_users['counts'] > 100) & (df_users['counts'] < 200)]['User-ID'])\n",
    "df.loc[df['User-ID'].isin(users)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating the reviews\n",
    "In this context, transactions are the reviews. You need to compile a list of lists, where each inner list contains reviews that are related, similar to how shopping lists are grouped in the example: `[['eggs','milk','bread'], ['bacon', 'bread'], [...], [...]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df.groupby('User-ID')['ISBN'].apply(list)\n",
    "reviewed = df_reviews.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the Support Confidence\n",
    "This requires some puzzling, but looking at the source code will give you a clear idea. You can reuse the subroutines in the source code and pass along the list containing the reviews belonging together. Play around with the _minimum support_ parameter. Too strict will result in fewer associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_itemsets_one(reviewed, min_sup=0.01):\n",
    "    N = len(reviewed)\n",
    "    print(N)\n",
    "    temp = defaultdict(int)\n",
    "    one_itemsets = dict()\n",
    "\n",
    "    for items in reviewed:\n",
    "        for item in items:\n",
    "            inx = frozenset({item})\n",
    "            temp[inx] += 1\n",
    "\n",
    "    print(\"temp:\")\n",
    "    i = 0\n",
    "    # remove all items that is not supported.\n",
    "    for key, itemset in temp.items():\n",
    "        #print(f\"{key}, {itemset}, {min_sup}, {min_sup * N}\")\n",
    "        if itemset > min_sup * N:\n",
    "            i = i + 1\n",
    "            one_itemsets[key] = itemset\n",
    "    print(i)\n",
    "    return one_itemsets\n",
    "\n",
    "def calculate_itemsets_two(reviewed, one_itemsets):\n",
    "    two_itemsets = defaultdict(int)\n",
    "\n",
    "    for items in reviewed:\n",
    "        items = list(set(items))  # remove duplications\n",
    "\n",
    "        if (len(items) > 2):\n",
    "            for perm in combinations(items, 2):\n",
    "                if has_support(perm, one_itemsets):\n",
    "                    two_itemsets[frozenset(perm)] += 1\n",
    "        elif len(items) == 2:\n",
    "            if has_support(items, one_itemsets):\n",
    "                two_itemsets[frozenset(items)] += 1\n",
    "    return two_itemsets\n",
    "\n",
    "def calculate_association_rules(one_itemsets, two_itemsets, N):\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    rules = []\n",
    "    for source, source_freq in one_itemsets.items():\n",
    "        for key, group_freq in two_itemsets.items():\n",
    "            if source.issubset(key):\n",
    "                target = key.difference(source)\n",
    "                support = group_freq / N\n",
    "                confidence = group_freq / source_freq\n",
    "                rules.append((timestamp, next(iter(source)), next(iter(target)),\n",
    "                              confidence, support))\n",
    "    return rules\n",
    "\n",
    "def has_support(perm, one_itemsets):\n",
    "  return frozenset({perm[0]}) in one_itemsets and \\\n",
    "    frozenset({perm[1]}) in one_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4238\n",
      "temp:\n",
      "274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sup = 0.01\n",
    "N = len(reviewed)\n",
    "\n",
    "one_itemsets = calculate_itemsets_one(reviewed, min_sup)\n",
    "two_itemset = calculate_itemsets_two(reviewed, one_itemsets)\n",
    "rules = calculate_association_rules(one_itemsets, two_itemset, N)\n",
    "\n",
    "len(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save the results\n",
    "Create a dataframe for the results of step 3. In order to make it work with the current app please make sure the columns are `source;target;support;confidence`. Save the recommendations as `recommendations-seeded-associations.csv` and replace the file in the app directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = []\n",
    "\n",
    "for rule in rules:\n",
    "    association = {\n",
    "        'source':str(rule[1]),\n",
    "        'target':str(rule[2]),\n",
    "        'confidence':rule[3],\n",
    "        'support':rule[4]\n",
    "    }\n",
    "    associations.append(association)\n",
    "\n",
    "df_associations = pd.DataFrame(associations)\n",
    "\n",
    "df_associations.to_csv('data/recommendations-seeded-associations.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
